---
title: "Correlation and Association"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, warning=FALSE, fig.width=8)
```


```{r}
# Get data
df <- params$data
df2 <- df
df <- df[,params$vars1,drop=FALSE]
```

```{r}
# Call used libraries 
library(knitr) # kable
library(fastDummies) # make dummies
library(lavaan)
library(semPlot)
library(corrplot)

eval <- FALSE
tryCatch({

# Drop columns if all observations are missing 
col_names_missing <- sapply(df, function(col) all(is.na(col)))
df[ ,col_names_missing] <- list(NULL)
df_list <- df 

# Drop empty rows
rowsums <- data.frame(sapply(df,is.na))
if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
  rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
  length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
  df <- df[-rows_drop, ,drop=FALSE]
}

# Drop columns with one unique value (NAs not considered)
cols_one <- sapply(df, function(col) length(unique(na.omit(col))) == 1)
df[,cols_one] <- list(NULL)

# Drop character variables with more than 10 categories, NAs included 
cols_catlarge <- sapply(df, function(col) is.character(col) & length(unique(col)) >10)
df[,cols_catlarge] <- list(NULL)

# Convert logical variables to character
cols_logical <- sapply(df, function(col) is.logical(col))
df[ ,cols_logical] <- sapply(df[ ,cols_logical], as.character)

# Extract continuous and ordinal variables 
df_num <- df[which(sapply(df, is.numeric) == 1L)]
rateunique_df <- sapply(df_num, function(col) (length(unique(na.omit(col))) / length(na.omit(col))) >= cutoffcont(length(na.omit(col))))
cols_continuous <- names(which(rateunique_df == TRUE))
cols_ordinal <- names(which(rateunique_df == FALSE))

# Extract binary character variables 
cols_binary <- sapply(df, function(col) is.character(col) & length(unique(na.omit(col))) == 2)
cols_binary_names <- names(which(cols_binary == TRUE))
df_binary <- df[,cols_binary,drop=FALSE]

# Make dummy variables for the character variables with more than 2 levels 
cols_dummy <- sapply(df, function(col) is.character(col) & length(unique(na.omit(col))) > 2)
df_dummy <-  df[,cols_dummy,drop=FALSE]
if (ncol(df_dummy)>0) {
  dummies <- fastDummies::dummy_cols(df_dummy, remove_first_dummy = TRUE, ignore_na=TRUE)
  dummies2 <- dummies[,-cols_dummy,drop=FALSE]
  df_binary <- merge(df_binary,dummies2,by="row.names")
} 

# Put together 
df_work <- merge(df_num,df_binary,by="row.names")
df_work$Row.names <- NULL
df_work$Row.names.y <-NULL

# Initialize next computations
eval <- TRUE

}, error=function(e) {
  
  stop(safeError("Outputs cannot be generated. Please check your data for consistency."))
  
}

)

```


```{r, results="asis", eval=eval}
# Chunk with first page of basic information

cat("\n# Basic Information", fill=TRUE)
cat("Automatic statistics for the file:", fill=TRUE)
dataname <- params$filename[1]
kable(dataname, col.names = "File")

cat("Your selection for the encoding:", fill=TRUE)
if (params$fencoding=="unknown"){
  cat("Auto")
} else {cat("UTF-8")}
cat("\\newline",fill=TRUE) 

cat("Your selection for the decimal character:", fill=TRUE)
if (params$decimal=="auto"){
  cat("Auto")
} else {cat(params$decimal)}
cat("\\newline",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("\\newline",fill=TRUE) 

# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("\\newline",fill=TRUE) 
}

cat("Variables (columns with at least one non-missing value): ", fill=TRUE)
cat(dim(df_list)[2])
cat("\\newline",fill=TRUE) 

cat("Variables considered continuous: ", fill=TRUE)
if (exists("df_num")){
  if (ncol(df_num)>0){
    if (sum(rateunique_df )>0){
      cat(sum(rateunique_df==TRUE),fill=TRUE)
      kable(cols_continuous, col.names = "Variables considered continuous")
    }
  } else {
    
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


cat("Numerical variables considered binary or ordinal: ", fill=TRUE)
if (exists("df_num")){
  if (ncol(df_num)>0){
    if (sum(rateunique_df==FALSE)>0){
      cat(sum(rateunique_df==FALSE),fill=TRUE)
      kable(cols_ordinal, col.names = "Numerical variables considered binary or ordinal")
    } else {
    
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}}


cat("Character variables considered binary: ", fill=TRUE)
if (exists("cols_binary")){
  if (sum(cols_binary)>0){
    cat(sum(cols_binary),fill=TRUE)
    kable(names(which(cols_binary==TRUE)), col.names = "Character variables considered binary")
  } else {
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


cat("Character variables considered norminal and transformed to binary: ", fill=TRUE)
if (exists("cols_dummy")){
  if (sum(cols_dummy)>0){
    cat(sum(cols_dummy),fill=TRUE)
    kable(colnames(dummies2), col.names = "Binary dummies for nominal variables")
  } else {
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


# Char with just one unique value not considered
if (exists("cols_one")){
  if (sum(cols_one) != 0L){
    cat("Columns with just one unique value (missings omitted) which are not considered in further computations: ")
    cat(sum(cols_one) ,fill=TRUE)
    cols <- names(which(cols_one==1))
    kable(cols, col.names = "Columns not considered")
  }
}

# Char > 10 not considered
if (exists("cols_catlarge")){
  if (sum(cols_catlarge) != 0L){
    cat("Character columns with more than 10 unique values which are not considered in further computations: ")
    cat(sum(cols_catlarge),fill=TRUE)
    cols <- names(which(cols_catlarge==1))
    kable(cols, col.names = "Columns not considered")
  }
}


# Missing columns
if (exists("col_names_missing")){
  if (sum(col_names_missing) != 0L){
    cat("\n\n\\small Number of columns that are dropped because they contain no values (all values are missing):", sum(col_names_missing))
    cat("\\newline",fill=TRUE) 
  } 
}

# Missings more than 50%
complete_rate <- sapply(df_work, function(col) 1-(sum(is.na(col)) / dim(df)[1])) 
if (length(which(complete_rate < 0.5)) != 0L){
  cat("**Warning: These variables have more than 50% missing values:**")
  miss_var <- names(which(complete_rate < 0.5)) 
  kable(miss_var, col.names = "Variable")
}


# Numeric falsly to char? 
check_reading <- function(col){
  numeric <- !is.na(as.numeric(col))
  return(sum(numeric)/sum(!is.na(col)))
}
numeric_percent <- sapply(df_dummy, function(col) check_reading(col))

if (length(numeric_percent[(numeric_percent>0.9)]) != 0L){
  cat("**Warning: More than 90% of the values of these columns could be treated as numeric. Nevertheless, because of some values or the selected decimal character, the columns must be treated as discrete. Are all the values plausible? Please check your data once more before uploading! Column(s):**", names(numeric_percent[(numeric_percent>0.9)]),fill=TRUE)
}
```

\pagebreak

```{r, results="asis", dev="cairo_pdf", eval=eval}

# Initialize next computations
eval2 <- FALSE

tryCatch({
  
  fit <- cfa(params$model, data=df_work, missing="fiml", estimator="ML", likelihood = "wishart") # to be like AMOS
  eval2 <- TRUE

}, error=function(e) {
  
  stop(safeError("Errors in the cfa execution. Please reconsider your data or your model."))
  
}

)
```     

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Model Syntax", fill=TRUE)
info <- inspect(fit, what="list")
info <- info[,c(2,3,4,5,8)]
cat("The following table describes the applied model equations in lavaan model syntax, either as entered by you in the text area (denoted by User=1) or established internally (User=0). The last column numbers the free parameters which are estimated.")
kable(info, col.names=c("Left hand side","Operator","Right hand side","User","Free parameter"))
```               

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Assumptions", fill=TRUE)
cat("bla", fill=TRUE)
```           

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Model Settings", fill=TRUE)
cat("bla", fill=TRUE)
```

```{r, dev="cairo_pdf", eval=eval2}

eval3<- FALSE
tryCatch({

  cat("# Lavaan Outputs", fill=TRUE)
  cat("## Model Summary", fill=TRUE)
  
  summary(fit, standardized=TRUE, fit.measures=TRUE)
  eval3 <- TRUE

}, error=function(e) {
  
  stop(safeError("Something went wrong while computing the summary statistics of the CFA. Please reconsider your data or your model."))
  
}

)

```


```{r, results="asis", dev="cairo_pdf", eval=eval2}

# Initiate indices
dfindic <- FALSE
chi1 <- FALSE
chi2 <- FALSE
cfi <- FALSE
tli <- FALSE

# Number of used variables
vars <- fit@pta$nvar[[1]]

cat("\n# Interpretation", fill=TRUE)
cat("\n## Overall Goodness of Fit", fill=TRUE)

# Chi2
cat("We consider fit indices from the Model Summary to check the overall goodness of fit. ", fill=TRUE)
cat("\\newline",fill=TRUE) 
cat("\\newline",fill=TRUE) 
cat("**Model Test User Model**", fill=TRUE)
cat("\\newline",fill=TRUE) 

if (fit@Fit@test$standard$df>0){
  cat("The degrees of freedom (df) are", fit@Fit@test$standard$df, "and positive, indicating an over-identified model, fact which basically enables further analysis and interpretation. ")
  dfindic <- TRUE
} else if (fit@Fit@test$standard$df==0){
   cat("The degrees of freedom (df) are", fit@Fit@test$standard$df, ", indicating a just-identified or saturated model. ")
} else {
  cat("The degrees of freedom (df)", fit@Fit@test$standard$df, "are negative, indicating an under-identified model, fact which basically disables further analysis and interpretation. ")
}

cat("Comment: The df are calculated as the number of known parameters minus the number of free parameters: ",(vars*(vars+1))/2+vars,"-",fit@Fit@npar,"=",fit@Fit@test$standard$df,". ")

eval3 <- eval2*dfindic
    
```

```{r, results="asis", dev="cairo_pdf", eval=eval3}

cat("The test statistic with the value ",round(fit@Fit@test$standard$stat,3),"is the chi-square test statistic representing the difference between summaries of the model-implied covariance matrix and the observed covariance matrix. It is a so called *absolute fit index*, evaluating the reasonability of the model without taking into account other possible solutions. ")

cat("The p-value of the test of a zero difference is ", pformat(fit@Fit@test$standard$pvalue))

if  (fit@Fit@test$standard$pvalue > 0.05){
  cat(". Therefore, the chi-square test of model fit is not statistically significant at 5% type I error suggesting an acceptable model fit. ")
  chi1 <- TRUE
} else {
  cat(". Therefore, the chi-square test of model fit is statistically significant at 5% type I error suggesting a non-acceptable model fit. ") 
}

cat("Nevertheless, this chi-square model fit index should not be used as a sole index of model fit since it greatly depends on the sample size and other model issues. Directly related is the chi-square to the degrees of freedom ratio: ", fit@Fit@test$standard$stat,"/",fit@Fit@test$standard$df,"=",round(fit@Fit@test$standard$stat/fit@Fit@test$standard$df,3))
  
if  (round(fit@Fit@test$standard$stat/fit@Fit@test$standard$df,3) < 3){
  cat(". This ratio is smaller than 3 (the cutoff used by Statsomat), suggesting an acceptable model fit. ")
  chi2 <- TRUE 
} else {
  cat(". This ratio is greater or equal than 3 (the cutoff used by Statsomat), suggesting a questionable or non-acceptable model fit. ") 
}

cat("Please consider that there is no universal agreed standard for the cutoff of this ratio. Other cutoff values may lead to other interpretations. ", fill=TRUE)
cat("\\newline",fill=TRUE) 
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**Model Test Baseline Model**", fill=TRUE)
cat("\\newline",fill=TRUE)
cat(" The test statistic with the value ",round(fit@baseline$test$standard$stat,3), " represents the difference between summaries of another model-implied covariance matrix with zero covariances (a baseline model assuming independent variables, i.e. a worst fitting model) and the observed covariance matrix. It is used only indirectly in a model fit index and not further commented here. ", fill=TRUE)
cat("\\newline",fill=TRUE) 
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**User Model versus Baseline Model**", fill=TRUE)
cat("\\newline",fill=TRUE)
cat(" The Comparative Fit Index (CFI),  evaluates the fit of the your model in relation to the worst-fitting baseline model (which assumes independent variables). ", fill=TRUE)

if (round(fitMeasures(fit)["cfi"],3)>0.9){
  cat("Your CFI value of ",round(fitMeasures(fit)["cfi"],3),"is greater than 0.90, suggesting an acceptable model. ")
  cfi <- TRUE
} else {
  cat("Your CFI value of ",round(fitMeasures(fit)["cfi"],3),"is smaller or equal than 0.90, suggesting a non-acceptable model. ")
}

```


```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("Notes: In our interpretation, we will use the term *variables* instead of *indicators* or *items*. ")
```

```{r, dev="cairo_pdf", eval=eval2}
# On the covariance matrix
inspect(fit, what="cov.ov") # Fitted cov
inspect(fit, "sampstat")$cov  # Observed cov 
resid(fit, "raw")$cov # Residuals on cov

# On the correlation matrix
inspect(fit, what="cor.ov") # Fitted corr
lavCor(fit) # Observed cor
r <- resid(fit, "cor")$cov # Residuals on cor
r
corrplot::corrplot(r, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75)
```  

```{r, dev="cairo_pdf", eval=eval2}
cat("\n## Parameter Estimates", fill=TRUE)
standardizedSolution(fit, type="std.all")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Path Diagram", fill=TRUE)
semPaths(fit)
```    
     
```{r, results="asis", eval=eval2}

tryCatch({

# Title 
cat("\n# R Statistical Methods", fill=TRUE)
cat("The statistical analysis was done using R [@stats]. ", fill=TRUE)
cat("\\newline",fill=TRUE)    
    
    
}, error=function(e) {cat("")}

)

```




---
title: "Correlation and Association"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, 
                      warning=FALSE, fig.width=8, booktabs = T, longtable = T, knitr.kable.NA = "") 
```


```{r}
# Get data
df <- params$data
df2 <- df
df <- df[,params$vars1,drop=FALSE]
```

```{r}
# Call used libraries 
library(knitr) # kable
library(fastDummies) # make dummies
library(lavaan)
library(semPlot)
library(corrplot)

eval <- FALSE
tryCatch({

# Drop columns if all observations are missing 
col_names_missing <- sapply(df, function(col) all(is.na(col)))
df[ ,col_names_missing] <- list(NULL)
df_list <- df 

# Drop empty rows
rowsums <- data.frame(sapply(df,is.na))
if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
  rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
  length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
  df <- df[-rows_drop, ,drop=FALSE]
}

# Drop columns with one unique value (NAs not considered)
cols_one <- sapply(df, function(col) length(unique(na.omit(col))) == 1)
df[,cols_one] <- list(NULL)

# Drop character variables with more than 10 categories, NAs included 
cols_catlarge <- sapply(df, function(col) is.character(col) & length(unique(col)) >10)
df[,cols_catlarge] <- list(NULL)

# Convert logical variables to character
cols_logical <- sapply(df, function(col) is.logical(col))
df[ ,cols_logical] <- sapply(df[ ,cols_logical], as.character)

# Extract continuous and ordinal variables 
df_num <- df[which(sapply(df, is.numeric) == 1L)]
rateunique_df <- sapply(df_num, function(col) (length(unique(na.omit(col))) / length(na.omit(col))) >= cutoffcont(length(na.omit(col))))
cols_continuous <- names(which(rateunique_df == TRUE))
cols_ordinal <- names(which(rateunique_df == FALSE))

# Extract binary character variables 
cols_binary <- sapply(df, function(col) is.character(col) & length(unique(na.omit(col))) == 2)
cols_binary_names <- names(which(cols_binary == TRUE))
df_binary <- df[,cols_binary,drop=FALSE]

# Make dummy variables for the character variables with more than 2 levels 
cols_dummy <- sapply(df, function(col) is.character(col) & length(unique(na.omit(col))) > 2)
df_dummy <-  df[,cols_dummy,drop=FALSE]
if (ncol(df_dummy)>0) {
  dummies <- fastDummies::dummy_cols(df_dummy, remove_first_dummy = TRUE, ignore_na=TRUE)
  dummies2 <- dummies[,-cols_dummy,drop=FALSE]
  df_binary <- merge(df_binary,dummies2,by="row.names")
} 

# Put together 
df_work <- merge(df_num,df_binary,by="row.names")
df_work$Row.names <- NULL
df_work$Row.names.y <-NULL

# Initialize next computations
eval <- TRUE

}, error=function(e) {
  
  stop(safeError("Outputs cannot be generated. Please check the data for consistency."))
  
}

)

```


```{r, results="asis", eval=eval}
# Chunk with first page of basic information

cat("\n# Basic Information", fill=TRUE)
cat("Automatic statistics for the file:", fill=TRUE)
dataname <- params$filename[1]
kable(dataname, col.names = "File")

cat("Your selection for the encoding:", fill=TRUE)
if (params$fencoding=="unknown"){
  cat("Auto")
} else {cat("UTF-8")}
cat("\\newline",fill=TRUE) 

cat("Your selection for the decimal character:", fill=TRUE)
if (params$decimal=="auto"){
  cat("Auto")
} else {cat(params$decimal)}
cat("\\newline",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("\\newline",fill=TRUE) 

# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("\\newline",fill=TRUE) 
}

cat("Variables (columns with at least one non-missing value): ", fill=TRUE)
cat(dim(df_list)[2])
cat("\\newline",fill=TRUE) 

cat("Variables considered continuous: ", fill=TRUE)
if (exists("df_num")){
  if (ncol(df_num)>0){
    if (sum(rateunique_df )>0){
      cat(sum(rateunique_df==TRUE),fill=TRUE)
      kable(cols_continuous, col.names = "Variables considered continuous")
    }
  } else {
    
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


cat("Numerical variables considered binary or ordinal: ", fill=TRUE)
if (exists("df_num")){
  if (ncol(df_num)>0){
    if (sum(rateunique_df==FALSE)>0){
      cat(sum(rateunique_df==FALSE),fill=TRUE)
      kable(cols_ordinal, col.names = "Numerical variables considered binary or ordinal")
    } else {
    
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}}


cat("Character variables considered binary: ", fill=TRUE)
if (exists("cols_binary")){
  if (sum(cols_binary)>0){
    cat(sum(cols_binary),fill=TRUE)
    kable(names(which(cols_binary==TRUE)), col.names = "Character variables considered binary")
  } else {
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


cat("Character variables considered nominal and transformed to binary: ", fill=TRUE)
if (exists("cols_dummy")){
  if (sum(cols_dummy)>0){
    cat(sum(cols_dummy),fill=TRUE)
    kable(colnames(dummies2), col.names = "Binary dummies for nominal variables")
  } else {
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


# Char with just one unique value not considered
if (exists("cols_one")){
  if (sum(cols_one) != 0L){
    cat("Columns with just one unique value (missings omitted) which are not considered in further computations: ")
    cat(sum(cols_one) ,fill=TRUE)
    cols <- names(which(cols_one==1))
    kable(cols, col.names = "Columns not considered")
  }
}

# Char > 10 not considered
if (exists("cols_catlarge")){
  if (sum(cols_catlarge) != 0L){
    cat("Character columns with more than 10 unique values which are not considered in further computations: ")
    cat(sum(cols_catlarge),fill=TRUE)
    cols <- names(which(cols_catlarge==1))
    kable(cols, col.names = "Columns not considered")
  }
}


# Missing columns
if (exists("col_names_missing")){
  if (sum(col_names_missing) != 0L){
    cat("\n\n\\small Number of columns that are dropped because they contain no values (all values are missing):", sum(col_names_missing))
    cat("\\newline",fill=TRUE) 
  } 
}

# Missings more than 50%
complete_rate <- sapply(df_work, function(col) 1-(sum(is.na(col)) / dim(df)[1])) 
if (length(which(complete_rate < 0.5)) != 0L){
  cat("**Warning: These variables have more than 50% missing values:**")
  miss_var <- names(which(complete_rate < 0.5)) 
  kable(miss_var, col.names = "Variable")
}


# Numeric falsly to char? 
check_reading <- function(col){
  numeric <- !is.na(as.numeric(col))
  return(sum(numeric)/sum(!is.na(col)))
}
numeric_percent <- sapply(df_dummy, function(col) check_reading(col))

if (length(numeric_percent[(numeric_percent>0.9)]) != 0L){
  cat("**Warning: More than 90% of the values of these columns could be treated as numeric. Nevertheless, because of some values or the selected decimal character, the columns must be treated as discrete. Are all the values plausible? Please check the data once more before uploading! Column(s):**", names(numeric_percent[(numeric_percent>0.9)]),fill=TRUE)
}
```

\pagebreak

```{r, results="asis", dev="cairo_pdf", eval=eval}

# Initialize next computations
eval2 <- FALSE

tryCatch({
  # No std of ov, default std of lv 
  fit <- cfa(params$model, data=df_work, missing="fiml", estimator="ML") 
  eval2 <- TRUE

}, error=function(e) {
  
  stop(safeError("Errors in the cfa execution. Please reconsider the data or the model."))
  
}, warning=function(w) {
  
  stop(safeError("Errors in the cfa execution. Please reconsider the data or the model."))
  
}

)


```     

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Model Syntax", fill=TRUE)
info <- inspect(fit, what="list")
info <- info[,c(2,3,4,5,8)]
cat("The following table describes the applied model equations in lavaan model syntax, either as entered by you in the text area (denoted by User=1) or established internally (User=0). The last column numbers the free parameters which are estimated.")
kable(info, col.names=c("Left hand side","Operator","Right hand side","User","Free parameter"))
```               

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Assumptions", fill=TRUE)
cat("Open issue", fill=TRUE)
```           

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Model Settings", fill=TRUE)
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Outputs", fill=TRUE)
cat("\n## Model Fit Summary", fill=TRUE)
```

```{r, dev="cairo_pdf", eval=eval2}

eval3<- FALSE
tryCatch({
  
  summary(fit, fit.measures=TRUE)
  eval3 <- TRUE
  
}, error=function(e) {
  
  stop(safeError("The summary statistics of the CFA cannot be computed error-free. Please reconsider the data or the model."))
  
}

)

```

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Completely Standardized Parameter Estimates", fill=TRUE)
```  

```{r, dev="cairo_pdf", eval=eval3}
fit2 <- cfa(params$model, data=df_work, missing="fiml", estimator="ML", std.ov=TRUE) 
standardizedSolution(fit2, type="std.all", output="text")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Communality", fill=TRUE)
pe <- parameterEstimates(fit, rsquare = TRUE)
r2 <- pe[pe$op=="r2",c(1,4)]
colnames(r2) <- c("Variable","Communality")
rownames(r2) <- NULL
kable(r2,caption="R-Square",digits=2, row.names = NA)
```  

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Observed Covariance Matrix", fill=TRUE)
obscov <- inspect(fit, "sampstat")$cov  
corrplot::corrplot(obscov, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")
```

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Fitted Covariance Matrix", fill=TRUE)
fittedcov <- inspect(fit, what="cov.ov") # Fitted cov
corrplot::corrplot(fittedcov, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")
```

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Residual Covariance Matrix", fill=TRUE)
covraw <- resid(fit, type="raw")$cov # Residuals on cov
corrplot::corrplot(covraw, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Standardized Residual Matrix", fill=TRUE)
covstd <-resid(fit, type="standardized")$cov # Std residuals on cov
corrplot::corrplot(covstd, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")

```  


```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Residual Correlation Matrix", fill=TRUE)

r <- resid(fit, "cor")$cov # Residuals on cor
corrplot::corrplot(r, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n## Modification Indices", fill=TRUE)

# MI for Correlation 
mi_corr <- modindices(fit, sort.=TRUE, power=TRUE, high.power = 0.75, na.remove=TRUE, op="~~")
mi_corr <- mi_corr[,c(-6,-8)]
rownames(mi_corr) <- NULL
if (nrow(mi_corr)>0){
  kable(mi_corr,col.names=c("Left","Operator","Right","Modification Index", "Expected Parameter Change", "Delta", "Power", "Decision"), digits=3, caption="Modification Indices With Respect To (Residual) Correlation")
}


# MI for Factor Loadings 
mi_fl <- modindices(fit, sort.=TRUE, power=TRUE, high.power = 0.75, na.remove=TRUE, op="=~", delta=0.4)
mi_fl <- mi_fl[,c(-6,-8)]
rownames(mi_fl) <- NULL
if (nrow(mi_fl)>0){
  kable(mi_fl,col.names=c("Left","Operator","Right","Modification Index", "Expected Parameter Change", "Delta", "Power", "Decision"), digits=3, caption="Modification Indices With Respect To Factor Loadings")
}

```

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("\n# Interpretation", fill=TRUE)
cat("\n## Goodness of Fit Indices", fill=TRUE)
cat("We consider some of the model fit indices from the Model Fit Summary section to check the goodness-of-fit of the model. To decide for an acceptable or non-acceptable model, we apply thresholds considered in the References: [@brown], [@kline]. ", fill=TRUE)
```

```{r, results="asis", dev="cairo_pdf", eval=eval3}
cat("**Model Test User Model**", fill=TRUE)
cat("\\newline",fill=TRUE) 

# Saturated vs non-saturated model 

# Number of in the model used indicator variables (observed variables)
vars <- fit@pta$nvar[[1]]

# Number of known parameter
knowns <- (vars*(vars+1))/2+vars # Single-group, FIML
# knowns <- (vars*(vars+1))/2 # Single-group, no FIML 

cat("The degrees of freedom are calculated as the number of known parameters minus the number of free parameters: ",knowns,"-",fit@Fit@npar,"=",fit@Fit@test$standard$df,". ")

if (fit@Fit@test$standard$df>0){
  cat("The ", fit@Fit@test$standard$df, "degrees of freedom indicate an over-identified model, fact which basically enables further analysis and interpretation. ")
  dfindic <- TRUE
} else if (fit@Fit@test$standard$df==0){
   cat("The ", fit@Fit@test$standard$df, "degrees of freedom are indicating a just-identified or saturated model. ")
   dfindic <- TRUE
} else {
  cat("The ", fit@Fit@test$standard$df, "degrees of freedom is a negative number, indicating an under-identified model. This disables further analysis and interpretation. ")
}


eval4 <- (eval3 && dfindic)
    
```

```{r, results="asis", dev="cairo_pdf", eval=eval4}
########
### Chi2
########

cat("The test statistic with the value ",round(fit@Fit@test$standard$stat,3)," is called the Chi-square model fit index and represents the difference between summaries of the model-implied covariance matrix and the observed covariance matrix which is hypothesized and desirable to be zero. In general, if the p-value is larger than",cutchi2(nrow(df_work))," then the test is not statistically significant at ",cutchi2(nrow(df_work))*100,"% error, the hypothesis cannot be rejected, which would be in favour of the model. ")
cat("\\newline",fill=TRUE)
cat("In our case, the p-value is ", pformat(fit@Fit@test$standard$pvalue))

if (round(fit@Fit@test$standard$pvalue,3) > cutchi2(nrow(df_work))){
  cat(" suggesting an acceptable model fit. ")
  chi2 <- 1L
} else {
  cat(" suggesting that the model may not be acceptable for the data. The Chi-square model fit index is based on a very stringent statistical hypothesis which may have no practical relevance. We will consider it only in connection with other model fit indices. ")
  chi2 <- 0L
} 

```

```{r, results="asis", dev="cairo_pdf", eval=eval4}
cat("**Model Test Baseline Model**", fill=TRUE)
cat("\\newline",fill=TRUE)

# Null model
cat("The test statistic with the value ",round(fit@baseline$test$standard$stat,3), " represents the difference between summaries of the baseline model (an alternative model-implied covariance matrix having zero covariances, i.e. a worst fitting model assuming independent variables) and the observed covariance matrix. ", fill=TRUE)

if (round(fit@baseline$test$standard$pvalue,3) > cutchi2(nrow(df_work))){
  cat("The p-value of the test of a zero difference is", pformat(fit@baseline$test$standard$pvalue)," suggesting that the baseline model would fit acceptable to the data. We will interpret this result in connection with other following model fit indices. ")
  nullmodell <- TRUE
} else {
  cat("The p-value of the test of a zero difference is", pformat(fit@baseline$test$standard$pvalue)," suggesting that the baseline model does not fit good to the data. This result is used indirectly in the construction of other model fit indices. ")
  nullmodell <- FALSE
}

# RMSEA null model =√{\frac{χ^2}{N \times df} - \frac{1}{N}} \times √{G}
rmseanull <- sqrt((fit@baseline$test$standard$stat-fit@baseline$test$standard$df)/(nrow(df_work)*fit@baseline$test$standard$df))

```

```{r, results="asis", dev="cairo_pdf", eval=eval4}

# RMSEA
cat("**Root Mean Square Error of Approximation:**", fill=TRUE)
cat("\\newline",fill=TRUE)
cat("The Root Mean Square Error of Approximation (RMSEA) is a fit index based on the chi-square test statistic, which corrects for parsimony, i.e. overly complex models are penalized. RMSEA can be greater or equal than zero, with values close to zero suggesting an acceptable model fit. ", fill=TRUE)
cat("\\newline",fill=TRUE)
cat("In our case, the RMSEA is ",round(fitMeasures(fit)["rmsea"],3))

if (round(fitMeasures(fit)["rmsea.ci.upper"],3)<0.05){
  cat(". The upper bound of the 90% confidence interval of the RMSEA is ",round(fitMeasures(fit)["rmsea.ci.upper"],3),"and smaller than the threshold value 0.05, suggesting an excellent model fit. ")
} else if (round(fitMeasures(fit)["rmsea.ci.upper"],3)<0.08){
  cat(". The upper bound of the 90% confidence interval of the RMSEA is ",round(fitMeasures(fit)["rmsea.ci.upper"],3),"and smaller than the threshold value 0.08, suggesting a good model fit. ")
} else if (round(fitMeasures(fit)["rmsea.ci.upper"],3)<0.1){
  cat(". The upper bound of the 90% confidence interval of the RMSEA is ",round(fitMeasures(fit)["rmsea.ci.upper"],3),"and smaller than the threshold value 0.1, suggesting an acceptable model fit. ")
} else {
  cat(". The upper bound of the 90% confidence interval of the RMSEA is ",round(fitMeasures(fit)["rmsea.ci.upper"],3),"and greater or equal than the threshold value 0.1, suggesting a poor model fit. ")
}

# David Kenny criterium 
if (rmseanull < 0.158){
  cat("Moreover, we compute also the RMSEA of the baseline model: ",rmseanull)
  if (nullmodel == TRUE){
    cat(". Its low value is in line with the p-value of the chi-square test with respect to the baseline model. This suggests that the average correlation between the variables is not so high. We will consider this result in the summary of the goodness of fit. ")
  } else {
    cat(". Its low value suggests that the average correlation between the variables is not so high. We will consider this result in the summary of the goodness of fit. ")
  }
}

rmsea0 <- (round(fitMeasures(fit)["rmsea.ci.upper"],3)<0.1)*1L
rmsea1 <- (round(fitMeasures(fit)["rmsea.ci.upper"],3)<0.08)*1L
rmsea2 <- (round(fitMeasures(fit)["rmsea.ci.upper"],3)<0.05)*1L
rmsea <- rmsea0 + rmsea1 + rmsea2 

```

```{r, results="asis", dev="cairo_pdf", eval=eval4}

# SRMR, liberal, depends highly on sample size
cat("**Standardized Root Mean Square Residual:**", fill=TRUE)
cat("\\newline",fill=TRUE)
cat("The Standardized Root Mean Square Residual (SRMR) is a fit index derived from the residual correlation matrix with a range between zero and one with values close to zero suggesting an acceptable model fit. ", fill=TRUE)
cat("\\newline",fill=TRUE)

if (round(fitMeasures(fit)["srmr"],2) < cutsrmr(nrow(df_work))){
   cat("In our case, the SRMR is ",round(fitMeasures(fit)["srmr"],2),"which is smaller than the threshold value ",cutsrmr(nrow(df_work))," suggesting an acceptable model fit. ")
} else {
   cat("In our case, the SRMR value is ",round(fitMeasures(fit)["srmr"],2),"which is greater or equal than the threshold value ",cutsrmr(nrow(df_work))," suggesting a poor model fit. ")
}

srmr <- (round(fitMeasures(fit)["srmr"],2) < cutsrmr(nrow(df_work)))*1L
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**User Model versus Baseline Model**", fill=TRUE)
cat("\\newline",fill=TRUE)

#####
# CFI
#####


# David Kenny 
if (rmseanull < 0.158){
  if (nullmodel == TRUE){
    cat("The chi-square test with respect to the baseline model and the low RMSEA of the baseline model suggest that the average correlation between the variables is not so high. Therefore, the CFI and the TLI indicate the departure from a baseline model which may be acceptable. In this case, the CFI and the TLI indices are poor model fit indices and will not be further evaluated. ")
  } else {
    cat("The low RMSEA of the baseline model suggests that the average correlation between the variables is not so high. Therefore, the CFI and the TLI indicate the departure from a baseline model which may be acceptable. In this case, the CFI and the TLI indices are poor model fit indices and will not be further evaluated. ")
  }
} else {


cat(" The Comparative Fit Index (CFI),  evaluates the fit of the the model in relation to the worst-fitting baseline model described above. It ranges between zero and one, with values close to one suggesting good models (in the sense of departure from the baseline model). ", fill=TRUE)
cat("\\newline",fill=TRUE)


if (round(fitMeasures(fit)["cfi"],3)>=0.95) {
  cat("In our case, the CFI is ",round(fitMeasures(fit)["cfi"],3),"which is greater or equal than the threshold value 0.95, suggesting a good model fit. ")
} else if (round(fitMeasures(fit)["cfi"],2)>=0.9){
  cat("In our case, the CFI is ",round(fitMeasures(fit)["cfi"],3),"which is greater or equal than the threshold value 0.90, suggesting an acceptable model fit. ")
} else {
  cat("In our case, the CFI is ",round(fitMeasures(fit)["cfi"],3),"which is smaller or equal than the threshold value 0.90, suggesting a poor model fit. ")
}

cfi1 <- (round(fitMeasures(fit)["cfi"],3)>=0.9)*1L
cfi2 <- (round(fitMeasures(fit)["cfi"],3)>=0.95)*1L
cfi <- cfi1 + cfi2 

}

```

```{r, results="asis", dev="cairo_pdf", eval=eval2}

#####
# TLI
#####


# David Kenny 
if (rmseanull >= 0.158){

cat("Similarly to the CFI, the Tucker-Lewis Index (TLI) evaluates the fit of the model in relation to the worst-fitting baseline model described above. Moreover, overly complex models are penalized. Values can range outside zero and one but the index is interpreted similarly to the CFI. ", fill=TRUE)
cat("\\newline",fill=TRUE)

  if (round(fitMeasures(fit)["tli"],3)>=0.95) {
    cat("In our case, the TLI is ",round(fitMeasures(fit)["tli"],3),"which is greater or equal than the threshold value 0.95, suggesting a good model fit. ")
  } else if (round(fitMeasures(fit)["tli"],3)>=0.9){
    cat("In our case, the TLI is ",round(fitMeasures(fit)["tli"],3),"which is greater or equal than the threshold value 0.90, suggesting an acceptable model fit. ")
  } else {
    cat("In our case, the TLI is ",round(fitMeasures(fit)["tli"],3),"which is smaller or equal than the threshold value 0.90, suggesting a poor model fit. ")
  }
  
  tli1 <- (round(fitMeasures(fit)["tli"],3)>=0.9)*1L
  tli2 <- (round(fitMeasures(fit)["tli"],3)>=0.95)*1L
  tli <- tli1 + tli2


}
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Summary of the Goodness of Fit Indices", fill=TRUE)

# David Kenny 
if (rmseanull < 0.158){
  
  # List considered indices 
  if (nullmodel == TRUE){
    cat("As specified above, the Chi-square test with respect to the baseline model and the low RMSEA of the baseline model suggest that the average correlation between the variables is not so high. In this case, the comparative fit indices CFI and TLI are poor model fit indices. Therefore, in the summary of the goodness of fit we consider only the Chi-square, the RMSEA and the SRMR model fit indices. ")
  } else {
    cat("As specified above, the low RMSEA of the baseline model suggests that the average correlation between the variables is not so high. In this case, the comparative fit indices CFI and TLI are poor model fit indices. Therefore, in the summary of the goodness of fit we consider only the Chi-square, the RMSEA and the SRMR model fit indices. ")
  }
  
  
  if (chi2 == 0L && srmr==0L && rmsea==0L){
    cat("All these fit indices suggest a poor model fit to the data. Therefore, we assume that the model is non-acceptable and proceed by diagnosing the sources of possible misspecification. ")
    step1<-0 
    
  } else if (chi2 == 0L && srmr == 1L && rmsea == 0L){
    cat("The Chi-square model fit index and the RMSEA suggest a non-acceptable model fit. On the other hand there is some support for the model from the SRMR fit index. We assume that the model is non-acceptable and proceed by diagnosing the sources of possible misspecification. ")
    step1<-1
    # A large sample size evtl. decreases the RMSEA and the SRMR indicates that the chi-square effect is not considerable. 
    # Lack of parsimony --> Too many free parameters ? 
   
  } else if (chi2 == 0L && srmr == 0L && rmsea > 0L){
    cat("The Chi-square model fit index and the SRMR suggest a non-acceptable model fit. On the other hand there exists support for the model from the RMSEA fit index. We tentatively give the model a chance to be accepted and proceed by diagnosing the sources of possible misspecification. ")
    step1<-2
    # Is this step realistic and possible? Sample size dependence to rigid for SRMR? 
    
  } else if (chi2 == 1L && rmsea == 0L && srmr == 1L){
    cat("The Chi-square and the SRMR model fit indices indicate an acceptable model fit. Even if the RMSEA suggests a poor model fit, we give the model a chance to be accepted and proceed by diagnosing the sources of possible misspecification. ")
    step1<-31
    # Is this step realistic and possible? 
    
  } else if (chi2 == 1L && rmsea == 0L && srmr == 0L){
    cat("The Chi-square model fit index suggests an acceptable model fit but the RMSEA and the SRMR suggest a non-acceptable model fit. We therefore tentatively assume a poor model fit and proceed by diagnosing the sources of possible misspecification. ")
    step1<-32
    # Power enough? Increase sample size? 
      
  } else if (chi2 == 1L && rmsea > 0L){
    cat("The Chi-square model fit index and the RMSEA suggest an acceptable model fit. We verify this assertion by considering further metrics. ")
    step1<-4
    # Great 
  } 
  
  
  
} else {  #(rmseanull >= 0.158)
  
  cat("In the summary of goodness of fit summary we consider the model fit indices: Chi-square, RMSEA, SRMR, TLI and by case also CFI. ")
  
  
  if (tli>0){

      if (chi2 == 0L && srmr==0L && rmsea==0L){
        cat("The absolute fit indices Chi-square, RMSEA and SRMR suggest a poor model fit. Therefore, we assume that the model is non-acceptable and proceed by diagnosing the sources of possible misspecification. ")
        step1<-6 
        
      } else if (chi2 == 0L && srmr == 1L && rmsea == 0L){
        cat("The Chi-square model fit index and the RMSEA suggest a poor model fit. On the other hand, there exists support for the model from the SRMR and TLI model fit indices. We therefore assume that the model is not excellent but eventually acceptable. We proceed by diagnosing the sources of possible misspecification. ")
        step1<-7
        # Lack of parsimony --> Too many free parameters? 
       
      } else if (chi2 == 0L && srmr == 0L && rmsea > 0L){
        cat("The Chi-square model fit index and the SRMR suggest a poor model fit. On the other hand, there exists support for the model from the RMSEA and TLI model fit indices. We therefore assume that the model is not excellent but acceptable. We proceed by diagnosing the sources of possible misspecification. ")
        step1<-8
        # Sample size issues 
        
      } else if (chi2 == 0L && srmr == 1L && rmsea > 0L){
        cat("All the indices besides the Chi-square model fit index suggest an acceptable model fit. The Chi-square model fit index is based on a very stringent statistical hypothesis. Therefore, we ignor it and tentatively assume an acceptable model fit. We verify this assertion by considering further metrics. ")
        step1<-9
        
      } else if (chi2 == 1L && rmsea == 0L){
        cat("The Chi-square model fit index and the TLI suggest an acceptable model fit. Even if the RMSEA suggests a poor model fit, we tentatively assume an acceptable model fit and verify this assertion by considering further metrics. ")
        step1<-10
        # Is this realistic?  
        
      } else if (chi2 == 1L && rmsea > 0L){
        cat("The Chi-square model fit index, the RMSEA and the TLI suggest an acceptable model fit. We tentatively assume an acceptable model fit and verify this assertion by considering further metrics. ")
        step1<-11
      } 
    
    
    
    
  } else { # tli==0
    
      if (cfi==0){
        cat("The comparative fit indices CFI and TLI suggest a poor model fit. Therefore, we assume a poor model fit and proceed by diagnosing the sources of possible misspecification. ")
        step1<-12 
        
      } else if (cfi>0){
        
          if (chi2 == 0L && srmr == 1L && rmsea == 0L){
            cat("There exists support for the model from the SRMR and CFI model fit indices. We therefore assume that the model is not excellent but eventually acceptable. We proceed by diagnosing the sources of possible misspecification. ")
            step1<-13
          # Lack of parsimony --> Too many free parameters? 
         
        } else if (chi2 == 0L && srmr == 0L && rmsea > 0L){
          cat("There exists support for the model from the RMSEA and CFI model fit indices. We therefore assume that the model is not excellent but acceptable. We proceed by diagnosing the sources of possible misspecification. ")
          step1<-14
          # Sample size issues 
          
        } else if (chi2 == 0L && srmr == 1L && rmsea > 0L){
          cat("All the indices besides the Chi-square model fit index and the TLI suggest an acceptable model fit. The Chi-square model fit index is based on a very stringent statistical hypothesis and the TLI suggests that the complexity of model could be reduced. We tentatively assume an acceptable model fit. We verify this assertion by considering further metrics. ")
          step1<-15
          # Lack of parsimony --> Too many free parameters? 
          
        } else if (chi2 == 1L && rmsea == 0L){
          cat("The Chi-square model fit index and the CFI suggest an acceptable model fit. The RMSEA and the TLI suggest a poor model fit. Therefore we assume that the model is not excellent but eventually acceptable. We proceed by diagnosing the sources of possible misspecification. ")
          step1<-16
          # Is this realistic?  
          
        } else if (chi2 == 1L && rmsea > 0L){
          cat("The Chi-square model fit index, the RMSEA and the CFI suggest an acceptable model fit. We tentatively assume an acceptable model fit and verify this assertion by considering further metrics. ")
          step1<-11
        } 
    
      }
    }
}



```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Residuals", fill=TRUE)
cat("We analyze the residual matrices from the Outputs chapter. The residual covariance matrix represents the difference between the observed covariance matrix and the fitted model-implied covariance matrix. Large absolute values indicate local areas of misfit. However, the residuals are affected by the raw metric and are difficult to interpret more precisely. ")
cat("\\newline",fill=TRUE)
cat("A better interpretation allows the standardized residual matrix (residuals divided by their estimated asymptotic standard error) and the residual correlation matrix. ")
cat("\\newline",fill=TRUE)

# Misfit areas 
if (nrow(stand_residuals(fit,"pos"))>0 || nrow(corr_residuals(fit,"pos"))>0){
  cat("Following variable pairs have standardized residuals which are larger or equal than the considered threshold 2.58 [@brown] or correlation residuals which are larger or equal than the considered threshold 0.1 [@kline]. In these cases, the zero-order covariance relationship between the involved variables is probably underestimated: ")
  both <- rbind(stand_residuals(fit,"pos"),corr_residuals(fit,"pos"))
  both <- both[order(both[,1],both[,2]),]
  both <- both[complete.cases(both),]
  both <- unique(both)
  rownames(both) <- paste("Pair",seq(1:nrow(both)))
  kable(both, col.names=c("Pair(s)",""), caption = "Pairs with Underestimated Covariance")
} else {
  cat("There are no variable pairs with standardized residuals which are larger or equal than the considered threshold 2.58 [@brown] or correlation residuals which are larger or equal than the considered threshold 0.1 [@kline]. Therefore, no relationships among the variables are substantially underestimated by the model. ")
}

if (nrow(stand_residuals(fit,"neg"))>0 || nrow(corr_residuals(fit,"neg"))>0){
 cat("Following variable pairs have standardized residuals which are smaller or equal than the considered threshold -2.58 [@brown] or correlation residuals which are smaller or equal than the considered threshold -0.1 [@kline]. In these cases, the zero-order covariance relationship between the involved variables is probably overestimated: ")
  both <- rbind(stand_residuals(fit,"neg"),corr_residuals(fit,"neg"))
  both <- both[order(both[,1],both[,2]),]
  both <- both[complete.cases(both),]
  both <- unique(both)
  rownames(both) <- paste("Pair",seq(1:nrow(both)))
  kable(both, col.names=c("Pair(s)",""), caption = "Pairs with Overestimated Covariance")
} else {
  cat("There are no variable pairs with standardized residuals which are smaller or equal than the considered threshold -2.58 [@brown] or correlation residuals which are smaller or equal than the considered threshold -0.1 [@kline]. Therefore, no relationships among the variables are substantially overestimated by the model. ")
}


if (nrow(stand_residuals(fit,"pos"))>0 || nrow(stand_residuals(fit,"neg"))>0){
  cat("Depending on the sample size, the misspecification detected by the analysis of the residual covariance resp. correlation matrices can be relevant or could be in practice neglected. This is matter of subject in the next section. ")
}
```  

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Modification Indices", fill=TRUE)
cat("In the interpretation of the modification indices we rely mostly on [@brown] and [@mi]. We cite from [@brown]: \"The modification index reflects an approximation of how much the overall model Chi² will decrease if the fixed or constrained parameter is freely estimated.\" In other words, if adding a line with a high modification index to the model, i.e. if adding a parameter, the overall goodness-of-fit may be improved. Nevertheless, this should be done only under certain conditions, described in the sequel. ")

cat("\\newline",fill=TRUE)
cat("We consider only modification indices greater or equal than 3.84. These represent modification indices which are statistically significant at 5% type I error. Next, we search only for modification indices which achieve a power of minimum 75% in detecting a (relevant) misspecification of at least 0.1 for (residual) correlations, respectively 0.4 for factor loadings. These are characterized in the decision column by the label \"epc:m\".", fill=TRUE)

# MI for correlation
mi_corr <- modindices(fit, minimum.value = 3.84, sort.=TRUE, power=TRUE, high.power = 0.75, na.remove=TRUE, op="~~")
mi_corr2 <- mi_corr[mi_corr$decision=="*epc:m*",c(-6,-8)]
if (nrow(mi_corr2)>0){
  kable(mi_corr2,col.names=c("Left","Operator","Right","Modification Index", "Expected Parameter Change", "Delta", "Power", "Decision"), digits=3, caption="Significant and Relevant MIs With Respect To (Residual) Correlations")
} else {
  cat("\\newline",fill=TRUE)
  cat("We remark, that these conditions are not fulfilled by any of the modification indices of the table xxx. Therefore, there are no significant and relevant modification indices with respect to (residual) correlations. ")
  }


# MI for factor loadings
mi_fl <- modindices(fit, minimum.value = 3.84, sort.=TRUE, power=TRUE, high.power = 0.75, na.remove=TRUE, op="=~", delta=0.4)
mi_fl2 <- mi_fl[mi_fl$decision=="*epc:m*",c(-6,-8)]
if (nrow(mi_fl2)>0){
  kable(mi_fl2,col.names=c("Left","Operator","Right","Modification Index", "Expected Parameter Change", "Delta", "Power", "Decision"), digits=3, caption="Significant and Relevant MIs With Respect To Factor Loadings")
} else {
  cat("\\newline",fill=TRUE)
  cat("We remark, that these conditions are not fulfilled by any of the modification indices of the table xxx. Therefore, there are no significant and relevant modification indices with respect to factor loadings. ")
  }
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
# Define standardized parameter estimates 
# fit2 <- cfa(params$model, data=df_work, missing="fiml", estimator="ML", std.ov=TRUE)  # already defined above 
pe_stand <- standardizedsolution(fit2, type="std.all")

# Define indicator for the existence of cross-loadings
if (cross_loadings(pe_stand)){
  cross_loadings_indic <- TRUE
} else {
  cross_loadings_indic <- FALSE
}

# Define indicator for the existence of error-covariances
if (error_covariances(pe_stand,fit2)){
  error_covariances_indic <- TRUE
} else {
  error_covariances_indic <- FALSE
}
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
# Factor Loadings
cat("\n##  Parameter Estimates", fill=TRUE)
cat("\n### Factor Loadings", fill=TRUE)
pvalues_stand <- pe_stand[which(pe_stand$op=="=~"),7]
estim_stand <- pe_stand[which(pe_stand$op=="=~"),4]
pe_stand_nonsig_nonrel <- pe_stand[which(pe_stand$pvalue>0.05 && pe_stand$op=="=~" && pe_stand$est.std<0.4),3]

# Significant and relevant
if ((sum(pvalues_stand > 0.05, na.rm = TRUE)==0) && (sum(abs(estim_stand) < 0.4, na.rm = TRUE)==0)) {
  cat("We remark that the completely standardized factor loadings (section \"Completely Standardized Parameter Estimates\") are all statistically significant at 5% type I error. Moreover, in absolute value they are all greater than 0.4. ")
  pe_stand_indic = "11"
  
} else if ((sum(pvalues_stand > 0.05, na.rm = TRUE) > 0)){
  cat("We remark that there exist completely standardized factor loadings (section \"Completely Standardized Parameter Estimates\") which are not statistically significant at 5% type I error (i.e. p-value > 0.05). ")
  
  # Non significant non relevant 
  if (length(pe_stand_nonsig_nonrel)>0){
    cat("Moreover, (some) non-significant completely standardized factor loadings are in absolute value smaller than 0.4. ")
    pe_stand_indic = "00"
  
    # Non significant but relevant   
  } else {
    cat("Nevertheless, the completely standardized factor loadings are in absolute value greater than 0.4. ")
    pe_stand_indic = "01"
  }
 
  # Significant but not relevant 
} else if ((sum(pvalues_stand > 0.05, na.rm = TRUE)==0) && (sum(abs(estim_stand) < 0.4, na.rm = TRUE)>0)) {
  cat("We remark that the completely standardized factor loadings (section \"Completely Standardized Parameter Estimates\") are all statistically significant at 5% type I error (i.e. p-value <= 0.05). Nevertheless, (some) completely standardized factor loadings are in absolute value smaller than 0.4. ")
  pe_stand_indic = "10" 
} 

cat("This cutoff-value is considered in some CFA research areas a magnitude that is substantively meaningful [@brown]. Please consider also cutoff-values from your particular research area when interpreting the factor loadings. ")
cat("We summarize the interpretation of the completely standardized factor loadings in the next table: ")


# Completely standardized factor loadings summary
library(kableExtra) # Only for this table
pe_stand2 <- pe_stand[pe_stand$op=="=~",c(1,3,4,7)]
colnames(pe_stand2)[2] <- "Variable"
pe_stand2$pvalue <- sapply(pe_stand2$pvalue,pformat)
## New column
pe_stand2$sig <- NA
pe_stand2$sig[which(pe_stand2$pvalue <= 0.05)] <- "Yes"  
pe_stand2$sig[which(pe_stand2$pvalue > 0.05)] <- "No" 
## New column
pe_stand2$rel <- NA
pe_stand2$rel[which(abs(pe_stand2$est.std) <= 0.4)] <- "!"
pe_stand2$rel[which(abs(pe_stand2$est.std) > 0.4)] <- "*"
pe_stand2$rel[which(abs(pe_stand2$est.std) > 0.6)] <- "**"
pe_stand2$rel[which(abs(pe_stand2$est.std) > 0.8)] <- "***"
## New column
pe_stand2$sign <- "Ok"
## New column
pe_stand2$keep <- "Ok"
pe_stand2$keep[which(pe_stand2$pvalue > 0.05 & abs(pe_stand2$est.std) <= 0.4)] <- paste0("Not relevant", footnote_marker_number(4, "latex"))
pe_stand2$keep[which(pe_stand2$pvalue > 0.05 & abs(pe_stand2$est.std) > 0.4)] <-  paste0("Uncertain", footnote_marker_number(5, "latex"))
pe_stand2$keep[which(pe_stand2$pvalue <= 0.05 & abs(pe_stand2$est.std) <= 0.4)] <- paste0("Uncertain", footnote_marker_number(6, "latex"))

## Colnames 
colnames(pe_stand2) <- c("Latent Variable","Observed Variable","Factor Loading","P-Value","Significant?","Relevance","Direction","Check")
names(pe_stand2)[3] <- paste0(names(pe_stand2)[3], footnote_marker_number(1, "latex"))
names(pe_stand2)[5] <- paste0(names(pe_stand2)[5], footnote_marker_number(2, "latex"))
names(pe_stand2)[6] <- paste0(names(pe_stand2)[6], footnote_marker_number(3, "latex"))

## Footnotes
if (cross_loadings(pe_stand)){
  one <- "The completely standardized factor loading can be interpreted as the correlation with the factor. "
} else {
  one <- "The completely standardized factor loading can be interpreted as a standardized regression coefficient. "
} 
two <- "5% type I error. "
three <- "Stars correspond to factor loadings cutoff-values: 0.4, 0.6, 0.8."
four <-  "The variable is probably not related to factor. "
five <- "Uncertain. The power of the test could be too low. "
six <- "Significant but smaller effect size. "
number = c(one,two,three,four,five,six)

## Kable
opts <- options(knitr.kable.NA = "")
x <- kable(pe_stand2, digits=2, escape = F, linesep = '', caption="Check Completely Standardized Factor Loadings", longtable = T)
footnote(x, number = number) %>%
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("hold_position", "repeat_header"))
```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
# Table Check Unstandardized Factor Loadings

pe <- parameterEstimates(fit, rsquare = TRUE)
pvalues_loadings <- pe[pe$op=="=~",]$pvalue

# Text 
cat("Next, we inspect the unstandardized factor loadings (section \"Model Fit Summary\"). ")
if ((sum(pvalues_loadings > 0.05, na.rm = TRUE)==0)) {
  cat("We remark that the unstandardized factor loadings are all statistically significant at 5% type I error. ")
  pe_unstand_indic = TRUE
  if (pe_stand_indic =="11" || pe_stand_indic =="10"){
    cat("Therefore, the significance test results for standardized and unstandardized factor loadings coincide (for non-marker variables). ")
  }
} else {
  cat("We remark that there exist unstandardized factor loadings which are not statistically significant at 5% type I error. ")
  pe_unstand_indic = FALSE
  if (pe_stand_indic =="00"){
    cat("Therefore, significance test results for both standardized and unstandardized factor loadings reveal relationships to latent variables which could be under certain conditions removed from the model. ")
  }
}

cat("We summarize the interpretation of the unstandardized factor loadings in the next table(s): ")

# Table 
library(kableExtra) # Only for this table
pe2 <- pe[pe$op=="=~",c(1,3,4,7)]
pe2$pvalue <- sapply(pe2$pvalue,pformat)
pe2$est <- round(pe2$est,2)
## New column
pe2$sig <- NA
pe2$sig[which(pe2$pvalue <= 0.05)] <- "Yes"  
pe2$sig[which(pe2$pvalue > 0.05)] <- "No" 
## New column
pe2$sign <- "Ok"
## Colnames
colnames(pe2) <- c("Latent Variable","Observed Variable","Factor Loading","P-Value","Significant?","Direction")
names(pe2)[5] <- paste0(names(pe2)[5], footnote_marker_number(1, "latex"))
## Footnotes
number = "5% type I error. "
## Kable
opts <- options(knitr.kable.NA = "")
x <- kable(pe2, digits=2, escape = F, linesep = '', caption="Check Unstandardized Factor Loadings", longtable = T)
footnote(x, number = number) %>%
  kable_styling(x, position = "center", full_width = FALSE, latex_options = c("hold_position", "repeat_header"))
```  

```{r, results="asis", dev="cairo_pdf", eval=pe_unstand_indic}
# Table Interpretation of Unstandardized Factor Loadings
text <-  function(df, cols){
  x <- df[df$op=="=~",3]
  duplicates <- which(duplicated(x))
  if (is.na(cols[4])){
    paste(cols[2],"is marker variable for",cols[1])
  } else if (cols[3]>=0){
    if (cols[2] %in% df[duplicates,3]){
      paste("A 1-unit increase in",cols[1],"leads to a",cols[3],"-unit increase in the",cols[2],"while the other factor(s) are held constant.")
    } else {
      paste("A 1-unit increase in",cols[1],"leads to a",cols[3],"-unit increase in the",cols[2])
    }
  } else {
    if (cols[2] %in% df[duplicates,3]){
      paste("A 1-unit increase in",cols[1],"leads to a",cols[3],"-unit decrease in the",cols[2],"while the other factor(s) are held constant.")
    } else {
      paste("A 1-unit increase in",cols[1],"leads to a",cols[3],"-unit decrease in the",cols[2])
    }
  }
}
opts <- options(knitr.kable.NA = "")
story <- apply(pe2, 1, function(cols) text(pe,cols))
knitr::kable(story, col.names="Interpretation of Unstandardized Factor Loadings",
             caption="Interpretation of Unstandardized Factor Loadings", linesep = '', longtable = T) %>%
  kable_styling(position = "center", latex_options = c("hold_position", "repeat_header"))
```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
# Factor covariances (completely stand.)
covariances_stand <- pe_stand[pe_stand$op=="~~",]
covariances_stand <- covariances_stand[covariances_stand$lhs != covariances_stand$rhs,]
factors <- fit@Model@dimNames[[3]][[1]]
covariances_stand <- covariances_stand[covariances_stand$lhs %in% factors,]
maxmin <- c(max(covariances_stand$est.std),min(covariances_stand$est.std))
which <- which.max(abs(maxmin))
max_corr <- maxmin[which]
factorcov <- covariances_stand[covariances_stand$lhs %in% factors,]
factorcov <- factorcov[abs(factorcov$est.std)>0.75,]
factorcov <- factorcov[,c(1,2,3,4)]

# Text 
cat("\n### Factor Correlations", fill=TRUE)
cat("As noted by [@brown], \"the interpretability of the size and statistical significance of factor intercorrelations depends on the specific research context. \"")
if (sum(abs(covariances_stand$est.std) > 0.75)==0){
  intercorr_indic = 0
  cat("Though, the largest estimated factor intercorrelation within the section \"Completely Standardized Parameter Estimates\" is",round(max_corr,2),"which we regard as a proof of a reasonable discriminant validity. ")
} else {
  cat("Still, large or statistically significant factor covariances are questionable and provide evidence of poor discriminant validity. There is evidence to question the distinctness of the following factors, since their correlation approaches in absolute value 1.0: ")
  intercorr_indic = 1
  rownames(factorcov) <- paste("Pair",seq(1:nrow(factorcov)))
  knitr::kable(factorcov,col.names = c("","","","Factor Correlation"), linesep = '',digits=2,
               caption="Factor Correlations")  %>%
    kable_styling(position = "center", latex_options = c("hold_position", "repeat_header"))
}
```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
# Factor Reliability (completely stand.)
cat("\n### Factor Reliability", fill=TRUE)
```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n### Error Variances", fill=TRUE)
variances <- pe_stand[pe_stand$op=="~~",]
variances <- variances[variances$lhs == variances$rhs,]
r2 <- pe[pe$op=="r2",c(1,4)]
variances <- merge(variances,r2,by="lhs")
variances$pvalue <- sapply(variances$pvalue,pformat)
variances$est.std <- round(variances$est.std,2)
## New column
variances$sig <- NA
variances$sig[which(variances$pvalue <= 0.05)] <- "Yes"  
variances$sig[which(variances$pvalue > 0.05)] <- "No" 
variances <- variances[,c(1,4,10,7,11)]

one <- "Can be interpreted as proportion of unexplained variance by the latent factor(s) (%). "
two <- "Corresponds to the squared factor loading."
three <- "Can be interpreted as proportion of explained variance by the latent factor(s) (%)."
four <- "5% type I error. Typically significant since a large portion of variance is not explained by the latent variable. "

if (cross_loadings(pe_stand)){
  footnote <- c(one,two,three,four)
  colnames(variances) <- c("Observed Variable","Error Variance","Communality","P-Value","Significant Error Variance?")
  names(variances)[2] <- paste0(names(variances)[2], footnote_marker_number(1, "latex"))
  names(variances)[3] <- paste0(names(variances)[3], footnote_marker_number(2, "latex"))
  names(variances)[3] <- paste0(names(variances)[3], footnote_marker_number(3, "latex"))
  names(variances)[5] <- paste0(names(variances)[5], footnote_marker_number(4, "latex"))
} else {
  footnote <- c(one,three,four)
  colnames(variances) <- c("Observed Variable","Error Variance","Communality","P-Value","Significant Error Variance?")
  names(variances)[2] <- paste0(names(variances)[2], footnote_marker_number(1, "latex"))
  names(variances)[3] <- paste0(names(variances)[3], footnote_marker_number(2, "latex"))
  names(variances)[5] <- paste0(names(variances)[5], footnote_marker_number(3, "latex"))
}

# Kable
opts <- options(knitr.kable.NA = "")
knitr::kable(variances, digits=2, escape = F, linesep = '', 
              caption="Completely Standardized Error Variances and Communality", longtable = T, align="l")  %>%
  footnote(number = footnote) %>%
  kable_styling(position = "center", latex_options = c("hold_position", "repeat_header"))
```  


```{r, results="asis", dev="cairo_pdf", eval=error_covariances_indic}
cat("\n### Error Correlations", fill=TRUE)
# Error covariances (completely stand.)
covariances_stand <- pe_stand[pe_stand$op=="~~",]
covariances_stand <- covariances_stand[covariances_stand$lhs != covariances_stand$rhs,]
ov <- fit@Model@dimNames[[4]][[1]]
covariances_error <- covariances_stand[covariances_stand$lhs %in% ov,]
covariances_error <- covariances_error[which(covariances_error$pvalue>0.05 || abs(covariances_error$est.std) <0.1),]
covariances_error$pvalue <- sapply(covariances_error$pvalue,pformat)
covariances_error <- covariances_error[,c(1,2,3,4,7)]
if (nrow(covariances_error)>0){
  cat("We remark, there exist error correlations which are not statistically significant at 5% type I error or which are are very small and below 0.1 (in absolute value). These error correlations may be unnecessary: ")
  rownames(covariances_error) <- paste("Pair",seq(1:nrow(covariances_error)))
  knitr::kable(covariances_error,col.names = c("","","","Error Covariance","P-Value"), linesep = '',digits=2,
               caption="Error Correlations")  %>%
    kable_styling(position = "center", latex_options = c("hold_position", "repeat_header"))
} else {
  cat("We remark, that all error covariances have completely standardized parameter estimates above 0.1 (in absolute value) and which are statistically significant at 5% type I error. Therefore, we assume that they are well defined in the model. ")
}

```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n### Intercepts", fill=TRUE)
cat("In case of missing values and estimation via FIML, a meanstructure i.e. the intercepts of the observed variables are added to the model. The means of the latent factors are fixed to zero. Therefore, the estimated intercepts within the section \"Model Fit Summary\" are just the means of the observed variables. ")
```  


```{r, results="asis", dev="cairo_pdf", eval=FALSE}
cat("\n## Final Summary", fill=TRUE)

cat("Please reconsider your data and the theory behind. ")

cat("\n### Eliminations", fill=TRUE)
cat("***Factors***", fill=TRUE) # given by factor covariances >0.85
cat("***Observed Variables***", fill=TRUE) # given by factor loadings < 0.4
cat("***Residual Covariances***", fill=TRUE) # given by non-sign or < 0.1 residual covariances  
cat("The variable is probably not related to factor. If also supported by theory, it could be dropped. ")
cat("Modificate and ideally replicate the CFA in an independent sample. ")
cat("Significant but smaller effect size. Is it acceptable for you? If not, further analysis would be recommended. ")
cat("Only if supported by theory, you could try to collapse the factors. ")
cat("If possible, increase sample size and repeat analysis. ")


cat("\n### Addings", fill=TRUE)
cat("***Factors***", fill=TRUE) # given by special pattern in stand. resid matrix 
cat("***Observed Variables***", fill=TRUE) # given by sig mod indices 
cat("***Residual Covariances***", fill=TRUE) # given by sig mod indices 
cat("Only if supported by the theory and research behind the data, you could try to update the model by a line recommended in the section \"Modification Indices \". Updating by adding a line means adding parameters to the model. The goodness-of-fit will be probably increased. ", fill=TRUE)
cat("Modificate and ideally replicate the CFA in an independent sample. ")

```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Path Diagram", fill=TRUE)
semPaths(fit, what="std", intercepts = FALSE)
```    
   
     



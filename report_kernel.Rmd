---
title: "Correlation and Association"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, warning=FALSE, fig.width=8)
```


```{r}
# Get data
df <- params$data
df2 <- df
df <- df[,params$vars1,drop=FALSE]
```

```{r}
# Call used libraries 
library(knitr) # kable
library(fastDummies) # make dummies
library(lavaan)
library(semPlot)
library(corrplot)

eval <- FALSE
tryCatch({

# Drop columns if all observations are missing 
col_names_missing <- sapply(df, function(col) all(is.na(col)))
df[ ,col_names_missing] <- list(NULL)
df_list <- df 

# Drop empty rows
rowsums <- data.frame(sapply(df,is.na))
if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
  rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
  length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
  df <- df[-rows_drop, ,drop=FALSE]
}

# Drop columns with one unique value (NAs not considered)
cols_one <- sapply(df, function(col) length(unique(na.omit(col))) == 1)
df[,cols_one] <- list(NULL)

# Drop character variables with more than 10 categories, NAs included 
cols_catlarge <- sapply(df, function(col) is.character(col) & length(unique(col)) >10)
df[,cols_catlarge] <- list(NULL)

# Convert logical variables to character
cols_logical <- sapply(df, function(col) is.logical(col))
df[ ,cols_logical] <- sapply(df[ ,cols_logical], as.character)

# Extract continuous and ordinal variables 
df_num <- df[which(sapply(df, is.numeric) == 1L)]
rateunique_df <- sapply(df_num, function(col) (length(unique(na.omit(col))) / length(na.omit(col))) >= cutoffcont(length(na.omit(col))))
cols_continuous <- names(which(rateunique_df == TRUE))
cols_ordinal <- names(which(rateunique_df == FALSE))

# Extract binary character variables 
cols_binary <- sapply(df, function(col) is.character(col) & length(unique(na.omit(col))) == 2)
cols_binary_names <- names(which(cols_binary == TRUE))
df_binary <- df[,cols_binary,drop=FALSE]

# Make dummy variables for the character variables with more than 2 levels 
cols_dummy <- sapply(df, function(col) is.character(col) & length(unique(na.omit(col))) > 2)
df_dummy <-  df[,cols_dummy,drop=FALSE]
if (ncol(df_dummy)>0) {
  dummies <- fastDummies::dummy_cols(df_dummy, remove_first_dummy = TRUE, ignore_na=TRUE)
  dummies2 <- dummies[,-cols_dummy,drop=FALSE]
  df_binary <- merge(df_binary,dummies2,by="row.names")
} 

# Put together 
df_work <- merge(df_num,df_binary,by="row.names")
df_work$Row.names <- NULL
df_work$Row.names.y <-NULL

# Initialize next computations
eval <- TRUE

}, error=function(e) {
  
  stop(safeError("Outputs cannot be generated. Please check your data for consistency."))
  
}

)

```


```{r, results="asis", eval=eval}
# Chunk with first page of basic information

cat("\n# Basic Information", fill=TRUE)
cat("Automatic statistics for the file:", fill=TRUE)
dataname <- params$filename[1]
kable(dataname, col.names = "File")

cat("Your selection for the encoding:", fill=TRUE)
if (params$fencoding=="unknown"){
  cat("Auto")
} else {cat("UTF-8")}
cat("\\newline",fill=TRUE) 

cat("Your selection for the decimal character:", fill=TRUE)
if (params$decimal=="auto"){
  cat("Auto")
} else {cat(params$decimal)}
cat("\\newline",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("\\newline",fill=TRUE) 

# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("\\newline",fill=TRUE) 
}

cat("Variables (columns with at least one non-missing value): ", fill=TRUE)
cat(dim(df_list)[2])
cat("\\newline",fill=TRUE) 

cat("Variables considered continuous: ", fill=TRUE)
if (exists("df_num")){
  if (ncol(df_num)>0){
    if (sum(rateunique_df )>0){
      cat(sum(rateunique_df==TRUE),fill=TRUE)
      kable(cols_continuous, col.names = "Variables considered continuous")
    }
  } else {
    
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


cat("Numerical variables considered binary or ordinal: ", fill=TRUE)
if (exists("df_num")){
  if (ncol(df_num)>0){
    if (sum(rateunique_df==FALSE)>0){
      cat(sum(rateunique_df==FALSE),fill=TRUE)
      kable(cols_ordinal, col.names = "Numerical variables considered binary or ordinal")
    } else {
    
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}}


cat("Character variables considered binary: ", fill=TRUE)
if (exists("cols_binary")){
  if (sum(cols_binary)>0){
    cat(sum(cols_binary),fill=TRUE)
    kable(names(which(cols_binary==TRUE)), col.names = "Character variables considered binary")
  } else {
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


cat("Character variables considered norminal and transformed to binary: ", fill=TRUE)
if (exists("cols_dummy")){
  if (sum(cols_dummy)>0){
    cat(sum(cols_dummy),fill=TRUE)
    kable(colnames(dummies2), col.names = "Binary dummies for nominal variables")
  } else {
    cat("0",fill=TRUE)
    cat("\\newline",fill=TRUE) }
}


# Char with just one unique value not considered
if (exists("cols_one")){
  if (sum(cols_one) != 0L){
    cat("Columns with just one unique value (missings omitted) which are not considered in further computations: ")
    cat(sum(cols_one) ,fill=TRUE)
    cols <- names(which(cols_one==1))
    kable(cols, col.names = "Columns not considered")
  }
}

# Char > 10 not considered
if (exists("cols_catlarge")){
  if (sum(cols_catlarge) != 0L){
    cat("Character columns with more than 10 unique values which are not considered in further computations: ")
    cat(sum(cols_catlarge),fill=TRUE)
    cols <- names(which(cols_catlarge==1))
    kable(cols, col.names = "Columns not considered")
  }
}


# Missing columns
if (exists("col_names_missing")){
  if (sum(col_names_missing) != 0L){
    cat("\n\n\\small Number of columns that are dropped because they contain no values (all values are missing):", sum(col_names_missing))
    cat("\\newline",fill=TRUE) 
  } 
}

# Missings more than 50%
complete_rate <- sapply(df_work, function(col) 1-(sum(is.na(col)) / dim(df)[1])) 
if (length(which(complete_rate < 0.5)) != 0L){
  cat("**Warning: These variables have more than 50% missing values:**")
  miss_var <- names(which(complete_rate < 0.5)) 
  kable(miss_var, col.names = "Variable")
}


# Numeric falsly to char? 
check_reading <- function(col){
  numeric <- !is.na(as.numeric(col))
  return(sum(numeric)/sum(!is.na(col)))
}
numeric_percent <- sapply(df_dummy, function(col) check_reading(col))

if (length(numeric_percent[(numeric_percent>0.9)]) != 0L){
  cat("**Warning: More than 90% of the values of these columns could be treated as numeric. Nevertheless, because of some values or the selected decimal character, the columns must be treated as discrete. Are all the values plausible? Please check your data once more before uploading! Column(s):**", names(numeric_percent[(numeric_percent>0.9)]),fill=TRUE)
}
```

\pagebreak

```{r, results="asis", dev="cairo_pdf", eval=eval}

# Initialize next computations
eval2 <- FALSE

tryCatch({
  
  fit <- cfa(params$model, data=df_work, missing="fiml", estimator="ML") 
  pe <- parameterEstimates(fit, standardized=TRUE)
  stdload <- pe[which(pe$op=="=~"),"std.all"]
  nfac <- fit@pta$nfac[[1]]
  eval2 <- TRUE

}, error=function(e) {
  
  stop(safeError("Errors in the cfa execution. Please reconsider your data or your model."))
  
}

)
```     

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Model Syntax", fill=TRUE)
info <- inspect(fit, what="list")
info <- info[,c(2,3,4,5,8)]
cat("The following table describes the applied model equations in lavaan model syntax, either as entered by you in the text area (denoted by User=1) or established internally (User=0). The last column numbers the free parameters which are estimated.")
kable(info, col.names=c("Left hand side","Operator","Right hand side","User","Free parameter"))
```               

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Assumptions", fill=TRUE)
cat("bla", fill=TRUE)
```           

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Model Settings", fill=TRUE)
cat("bla", fill=TRUE)
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Outputs", fill=TRUE)
cat("\n## Model Summary", fill=TRUE)
```

```{r, dev="cairo_pdf", eval=eval2}

eval3<- FALSE
tryCatch({
  
  summary(fit, standardized=TRUE, fit.measures=TRUE)
  eval3 <- TRUE
  
}, error=function(e) {
  
  stop(safeError("The summary statistics of the CFA cannot be computed error-free. Please reconsider your data or your model."))
  
}

)

```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Residual covariance matrix", fill=TRUE)

# Covariance matrix
# inspect(fit, "sampstat")$cov  # Observed cov 
# inspect(fit, what="cov.ov") # Fitted cov
covraw <- resid(fit, type="raw")$cov # Residuals on cov
cat("We vizualize the residual covariance matrix, which is the difference between the sample and the model-implied covariance matrix: ")
cat("\\newline",fill=TRUE)   
corrplot::corrplot(covraw, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Standardized residual matrix", fill=TRUE)

covstd <-resid(fit, type="standardized")$cov # Std residuals on cov
cat("A better interpretation allows the standardized residual matrix (fitted residuals divided by their estimated standard errors): ")
cat("\\newline",fill=TRUE)   
corrplot::corrplot(covstd, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")

```  


```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Residual correlation matrix", fill=TRUE)

# Correlation matrix
# inspect(fit, what="cor.ov") # Fitted corr
# lavCor(fit) # Observed cor
r <- resid(fit, "cor")$cov # Residuals on cor
cat("We consider and vizualize also the residual correlation matrix, which is the difference between the sample and the model-implied covariance matrix: ")
cat("\\newline",fill=TRUE)   
corrplot::corrplot(r, is.corr = FALSE,
               type = 'lower',
               order = "original",
               tl.col='black', tl.cex=.75, number.cex=0.75, method="number")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Modification Indices:", fill=TRUE)

cat("We consider the modification indices larger than four, in descending order: ", fill=TRUE)
mi <- modindices(fit,minimum.value = 4)
mi2 <- mi[order(-mi$mi),c(1:4)]
rownames(mi2) <- NULL
if (nrow(mi)>0){
  kable(mi2,col.names=c("Left hand side","Operator","Right hand side","Modification Index"), digits=3)
}
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Interpretation", fill=TRUE)
cat("\n## Goodness of Fit Indices", fill=TRUE)
cat("We consider selected fit indices from the Model Summary to check the goodness of fit of the model. Values from the Model Summary are rounded where appropiately. We consider following classes for the goodness of fit: Non-acceptable, mediocre, acceptable and good. Our interpretation is based mainly on [@cfa] and [@kline] and afferent articles. ", fill=TRUE)
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**Model Test User Model**", fill=TRUE)
cat("\\newline",fill=TRUE) 

# Saturated vs non-saturated model 

# Number of in the model used indicator variables
vars <- fit@pta$nvar[[1]]

# Number of knowns
knowns <- (vars*(vars+1))/2+vars # Single-group, FIML
# knowns <- (vars*(vars+1))/2 # Single-group, no FIML 


if (fit@Fit@test$standard$df>0){
  cat("The degrees of freedom (df) are", fit@Fit@test$standard$df, "and positive, indicating an over-identified model, fact which basically enables further analysis and interpretation. ")
  dfindic <- TRUE
} else if (fit@Fit@test$standard$df==0){
   cat("The degrees of freedom (df) are", fit@Fit@test$standard$df, ", indicating a just-identified or saturated model. ")
} else {
  cat("The degrees of freedom (df)", fit@Fit@test$standard$df, "are negative, indicating an under-identified model, fact which basically disables further analysis and interpretation. ")
}

cat("Comment: The df are calculated as the number of known parameters minus the number of free parameters: ",knowns,"-",fit@Fit@npar,"=",fit@Fit@test$standard$df,". ")

eval3 <- (eval2 && dfindic)
    
```

```{r, results="asis", dev="cairo_pdf", eval=eval3}
########
### Chi2
########

cat("The test statistic with the value ",round(fit@Fit@test$standard$stat,3),"represents the difference between summaries of the model-implied covariance matrix and the observed covariance matrix. ")
cat("The p-value of the test of a zero difference is ", pformat(fit@Fit@test$standard$pvalue),". ")
cat("A positive chi-square model fit index is usually determined by a p-value larger than the threshold value 0.05. The chi-square model fit index is an absolute fit index which heavily depends on several data and model characteristics e.g. sample size, number of factors and other. Therefore, we will not consider it in the overall goodness of fit summary. ")

```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**Model Test Baseline Model**", fill=TRUE)
cat("\\newline",fill=TRUE)

# Null model
cat(" The test statistic with the value ",round(fit@baseline$test$standard$stat,3), " represents the difference between summaries of the baseline model (another model-implied covariance matrix having zero covariances, a worst fitting model assuming independent variables) and the observed covariance matrix. ", fill=TRUE)

if (fit@baseline$test$standard$pvalue > 0.05){
  cat("The p-value of the test of a zero difference is", pformat(fit@baseline$test$standard$pvalue)," suggesting that the baseline model would fit acceptable to the data. ")
  nullmodell <- TRUE
} else {
  nullmodell <- FALSE
}

# RMSEA null model =√{\frac{χ^2}{N \times df} - \frac{1}{N}} \times √{G}
rmseanull <- sqrt((fit@baseline$test$standard$stat-fit@baseline$test$standard$df)/(nrow(df_work)*fit@baseline$test$standard$df))

```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**User Model versus Baseline Model**", fill=TRUE)
cat("\\newline",fill=TRUE)

#####
# CFI
#####

cat(" The Comparative Fit Index (CFI),  evaluates the fit of the your model in relation to the worst-fitting baseline model described above. It ranges between zero and one, with values close to one suggesting good models. ", fill=TRUE)

if (round(fitMeasures(fit)["cfi"],2)>=0.95) {
  cat("Your CFI value of ",round(fitMeasures(fit)["cfi"],2),"is greater or equal than the threshold value 0.95, suggesting a good model fit. ")
} else if (round(fitMeasures(fit)["cfi"],2)>=0.9){
  cat("Your CFI value of ",round(fitMeasures(fit)["cfi"],2),"is greater or equal than the threshold value 0.90, suggesting an acceptable model fit. ")
} else {
  cat("Your CFI value of ",round(fitMeasures(fit)["cfi"],2),"is smaller or equal than the threshold value 0.90, suggesting a mediocre or non-acceptable model fit. ")
}

cfi1 <- (round(fitMeasures(fit)["cfi"],2)>=0.9)*1L
cfi2 <- (round(fitMeasures(fit)["cfi"],2)>=0.95)*1L
cfi <- cfi1 + cfi2 

```

```{r, results="asis", dev="cairo_pdf", eval=eval2}

# TLI
cat("The Tucker-Lewis Index (TLI), evaluates the fit of the your model in relation to the worst-fitting baseline model described above. Overly complex models are penalized. Values can range outside zero and one but the index is interpreted similarly to CFI. ", fill=TRUE)

if (round(fitMeasures(fit)["tli"],2)>=0.95) {
  cat("Your TLI value of ",round(fitMeasures(fit)["tli"],2),"is greater or equal than the threshold value 0.95, suggesting a good model fit. ")
} else if (round(fitMeasures(fit)["cfi"],2)>=0.9){
  cat("Your TLI value of ",round(fitMeasures(fit)["tli"],2),"is greater or equal than the threshold value 0.90, suggesting an acceptable model fit. ")
} else {
  cat("Your TLI value of ",round(fitMeasures(fit)["tli"],2),"is smaller or equal than the threshold value 0.90, suggesting a mediocre or non-acceptable model fit. ")
}

tli1 <- (round(fitMeasures(fit)["tli"],2)>=0.9)*1L
tli2 <- (round(fitMeasures(fit)["tli"],2)>=0.95)*1L
tli <- tli1 + tli2
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}

# RMSEA
cat("**Root Mean Square Error of Approximation:**", fill=TRUE)
cat("\\newline",fill=TRUE)
cat("The Root Mean Square Error of Approximation (RMSEA) is an absolute fit index based on the chi-square test statistic, which corrects for parsimony. Overly complex models are penalized. Values can be greater or equal than zero, with values close to zero suggesting an acceptable model fit. ", fill=TRUE)

if (round(fitMeasures(fit)["rmsea.ci.upper"],2)<0.06){
  cat("The upper bound of the 90% confidence interval of the RMSEA: ",round(fitMeasures(fit)["rmsea.ci.upper"],2),"is smaller than the threshold value 0.06, suggesting a good model fit. ")
} else if (round(fitMeasures(fit)["rmsea.ci.upper"],2)<0.08){
  cat("The upper bound of the 90% confidence interval of the RMSEA: ",round(fitMeasures(fit)["rmsea.ci.upper"],2),"is smaller than the threshold value 0.08, suggesting an acceptable model fit. ")
} else if (round(fitMeasures(fit)["rmsea.ci.upper"],2)<0.1){
  cat("The upper bound of the 90% confidence interval of the RMSEA: ",round(fitMeasures(fit)["rmsea.ci.upper"],2),"is smaller than the threshold value 0.1, suggesting a mediocre fit. ")
} else {
  cat("The upper bound of the 90% confidence interval of the RMSEA: ",round(fitMeasures(fit)["rmsea.ci.upper"],2),"is greater or equal than the threshold value 0.1, suggesting a non-acceptable model fit. ")
}

# David Kenny criterium 
if (rmseanull < 0.158){
  cat("Moreover, we compute also the RMSEA of the baseline model: ",rmseanull)
  if (nullmodel == TRUE){
    cat(". Its low value is in line with the p-value of the chi-square test with respect to the baseline model. This suggests that the average correlation between the variables is not so high. ")
  } else {
    cat(". Its low value suggests that the average correlation between the variables is not so high. ")
  }
}

rmsea0 <- (round(fitMeasures(fit)["rmsea.ci.upper"],2)<0.1)*1L
rmsea1 <- (round(fitMeasures(fit)["rmsea.ci.upper"],2)<0.08)*1L
rmsea2 <- (round(fitMeasures(fit)["rmsea.ci.upper"],2)<0.06)*1L
rmsea <- rmsea0 + rmsea1 + rmsea2 

```

```{r, results="asis", dev="cairo_pdf", eval=eval2}

# SRMR, liberal, depends highly on sample size
cat("**Standardized Root Mean Square Residual:**", fill=TRUE)
cat("\\newline",fill=TRUE)
cat("The Standardized Root Mean Square Residual (SRMR) is an absolute model fit index derived from the residual correlation matrix with a range between zero and one with values close to zero suggesting an acceptable model fit. ", fill=TRUE)

cat("\\newline",fill=TRUE)

if (round(fitMeasures(fit)["srmr"],2) < cutsrmr(nrow(df_work))){
   cat("The SRMR value of ",round(fitMeasures(fit)["srmr"],2),"is smaller than the threshold value ",cutsrmr(nrow(df_work))," suggesting an at least acceptable model fit. ")
} else {
   cat("The SRMR value of ",round(fitMeasures(fit)["srmr"],2),"is greater or equal than the threshold value ",cutsrmr(nrow(df_work))," suggesting a mediocre or non-acceptable model fit. ")
}

srmr <- (round(fitMeasures(fit)["srmr"],2) < cutsrmr(nrow(df_work)))*1L
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**Our Model Fit Indices Summary:**", fill=TRUE)
cat("\\newline",fill=TRUE)  

# David Kenny 
if (rmseanull < 0.158){
  if (nullmodel == TRUE){
    cat(". The chi-square test with respect to the baseline model and the low RMSEA of the baseline model suggest that the average correlation between the variables is not so high. In this case, the comparative model fit indices CFI and TLI may be too low, indicating just a small departure from the acceptable baseline model. Therefore, we consider in the summary of model indices only the RMSEA and the SRMR. ")
  } else {
    cat(".  the low RMSEA of the baseline model suggest that the average correlation between the variables is not so high. In this case, the comparative model fit indices CFI and TLI may be too low, indicating just a small departure from the acceptable baseline model. Therefore, we do not consider them in the summary of model indices. ")
  }
  
  if (srmr==0 && rmsea==0){
    cat("The absolute fit indices suggest a poor respectively non-acceptable model fit. ")
    cat("Please reconsider your data and the theory behind. Moreover, unless you have exhausted reasonable respecifications, you could try to respecificate your model. ")  
  } else if (srmr != rmsea){
    cat("There is some support for your model. ")
    cat("Please consider that the model may be not better than the baseline model. ")
  } else if (srmr > 0 && rmsea > 0){
    cat("The absolute fit indices suggest that your model is acceptable for your data. ")
    cat("Please consider that the model may be not better than the baseline model. ")
  }
}

  
if (rmseanull >= 0.158){
  cat("We consider in our summary only the model indices TLI, RMSEA and the SRMR. ")

  if (tli ==0 && srmr==0 && rmsea==0){
    cat("Absolute and comparative indices suggest a poor goodness of fit of the model. ")
  } else if (tli >= 1 && srmr==0 && rmsea == 0) {
      cat("Your model is better than the baseline model. Nevertheless, the absolute fit indices suggest a poor resp. a non-acceptable model fit. ")
      cat("Unless you have exhausted reasonable respecifications, you could try to respecificate your model. ")  
  } else if (tli == 1 && srmr==1 && rmsea == 0) {
      cat("")
  }

  
}





  
  
  


```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n## Localized Area of Strain", fill=TRUE)
cat("**Residuals:**", fill=TRUE)
cat("\\newline",fill=TRUE)  
cat("In the next step, we investigate the residuals and the modification indices, which are \"frequently used to identify focal areas of misfit in CFA solution\" [@cfa]. ", fill=TRUE)
cat("We vizualize the residual covariance matrix, which is the difference between the sample and the model-implied covariance matrix. Large absolute values tend to indicate areas of misfit. ")
cat("A better interpretation allows the standardized residual matrix. We assume that absolute values larger than the threshold 2.58 [@byrne] indicate areas of misfit. ")
cat("We consider and vizualize also the residual correlation matrix. We assume that absolute values larger than the threshold 0.1 indicate areas of misfit. ")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("**Modification Indices:**", fill=TRUE)
cat("\\newline",fill=TRUE)  
if (nrow(mi)>0){
  cat("The table is sorted in descending order of the modification index. Only if supported by the theory and research behind your data, you could try to update the model by a line with a high modification index and repeat the evaluation. The goodness of fit will be probably increased. ", fill=TRUE)
}
```

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n##  Parameter Estimates", fill=TRUE)
```  

```{r, dev="cairo_pdf", eval=eval2}
standardizedSolution(fit, type="std.all")
```  

```{r, results="asis", dev="cairo_pdf", eval=eval2}
cat("\n# Path Diagram", fill=TRUE)
semPaths(fit)
```    
     
```{r, results="asis", eval=eval2}

tryCatch({

# Title 
cat("\n# R Statistical Methods", fill=TRUE)
cat("The statistical analysis was done using R [@stats]. ", fill=TRUE)
cat("In our interpretation, we will use the term *variables* instead of *indicators* or *items*. ")
cat("\\newline",fill=TRUE)    
    
    
}, error=function(e) {cat("")}

)

```



